{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "446_final_proj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6P6r3SJUuBZ"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as func"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcYU0UrrIloS"
      },
      "source": [
        "# CUDA for PyTorch\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\r\n",
        "torch.backends.cudnn.benchmark = True\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d49EabWtXjwS"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItFQAFcpgj5O"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duAprHJygmhb"
      },
      "source": [
        "traindir = \"/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/\"\r\n",
        "valdir = \"/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/\"\r\n",
        "testdir = \"/content/drive/MyDrive/FA20_CS446_Project_Data/test_pub/\"\r\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1BBXnWxoKnL"
      },
      "source": [
        "class np_Dataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, np_file_paths, np_label_paths):\r\n",
        "        self.files = np_file_paths\r\n",
        "        self.label = np_label_paths\r\n",
        "    \r\n",
        "    def __getitem__(self, index):\r\n",
        "        x = np.load(self.files[index])\r\n",
        "        x = torch.from_numpy(x).float()\r\n",
        "\r\n",
        "        y = np.load(self.label[index])\r\n",
        "        y = torch.from_numpy(y).int()\r\n",
        "\r\n",
        "        return x, y\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.files)\r\n",
        "\r\n",
        "class np_final_dataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, np_file_paths):\r\n",
        "        self.files = np_file_paths\r\n",
        "    \r\n",
        "    def __getitem__(self, index):\r\n",
        "        x = np.load(self.files[index])\r\n",
        "        x = torch.from_numpy(x).float()\r\n",
        "\r\n",
        "        return x\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.files)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7kaycFxofot",
        "outputId": "eddf3af3-5391-4f47-f58f-46a01d88a957"
      },
      "source": [
        "from os import walk\r\n",
        "\r\n",
        "t_d = []\r\n",
        "t_l = []\r\n",
        "for (dirpath, dirnames, filenames) in walk(traindir):\r\n",
        "    t_d = [(traindir + f) for f in filenames if f.endswith('imgs.npy')]\r\n",
        "    t_d.sort()\r\n",
        "    t_l = [traindir + f for f in filenames if f.endswith('seg.npy')]\r\n",
        "    t_l.sort()\r\n",
        "    break\r\n",
        "\r\n",
        "v_d = []\r\n",
        "v_l = []\r\n",
        "for (dirpath, dirnames, filenames) in walk(valdir):\r\n",
        "    v_d = [valdir + f for f in filenames if f.endswith('imgs.npy')]\r\n",
        "    v_d.sort()\r\n",
        "    v_l = [valdir + f for f in filenames if f.endswith('seg.npy')]\r\n",
        "    v_l.sort()\r\n",
        "    break\r\n",
        "  \r\n",
        "test = []\r\n",
        "\r\n",
        "for (dirpath, dirnames, filenames) in walk(testdir):\r\n",
        "  test = [testdir + f for f in filenames if f.endswith('imgs.npy')]\r\n",
        "  test.sort()\r\n",
        "  break\r\n",
        "\r\n",
        "print(t_d+v_d)\r\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/001_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/002_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/003_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/004_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/005_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/006_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/007_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/008_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/009_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/010_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/011_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/012_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/013_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/014_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/015_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/016_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/017_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/018_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/019_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/020_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/021_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/022_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/023_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/024_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/025_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/026_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/027_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/028_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/029_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/030_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/031_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/032_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/033_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/034_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/035_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/036_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/037_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/038_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/039_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/040_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/041_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/042_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/043_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/044_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/045_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/046_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/047_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/048_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/049_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/050_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/051_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/052_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/053_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/054_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/055_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/056_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/057_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/058_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/059_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/060_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/061_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/062_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/063_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/064_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/065_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/066_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/067_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/068_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/069_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/070_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/071_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/072_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/073_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/074_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/075_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/076_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/077_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/078_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/079_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/080_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/081_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/082_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/083_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/084_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/085_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/086_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/087_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/088_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/089_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/090_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/091_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/092_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/093_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/094_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/095_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/096_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/097_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/098_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/099_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/100_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/101_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/102_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/103_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/104_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/105_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/106_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/107_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/108_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/109_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/110_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/111_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/112_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/113_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/114_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/115_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/116_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/117_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/118_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/119_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/120_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/121_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/122_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/123_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/124_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/125_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/126_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/127_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/128_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/129_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/130_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/131_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/132_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/133_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/134_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/135_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/136_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/137_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/138_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/139_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/140_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/141_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/142_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/143_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/144_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/145_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/146_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/147_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/148_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/149_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/150_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/151_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/152_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/153_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/154_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/155_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/156_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/157_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/158_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/159_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/160_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/161_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/162_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/163_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/164_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/165_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/166_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/167_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/168_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/169_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/170_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/171_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/172_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/173_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/174_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/175_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/176_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/177_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/178_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/179_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/180_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/181_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/182_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/183_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/184_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/185_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/186_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/187_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/188_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/189_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/190_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/191_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/192_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/193_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/194_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/195_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/196_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/197_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/198_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/199_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/200_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/201_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/202_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/203_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/train/204_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/001_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/002_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/003_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/004_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/005_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/006_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/007_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/008_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/009_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/010_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/011_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/012_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/013_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/014_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/015_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/016_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/017_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/018_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/019_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/020_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/021_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/022_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/023_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/024_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/025_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/026_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/027_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/028_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/029_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/030_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/031_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/032_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/033_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/034_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/035_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/036_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/037_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/038_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/039_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/040_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/041_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/042_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/043_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/044_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/045_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/046_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/047_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/048_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/049_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/050_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/051_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/052_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/053_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/054_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/055_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/056_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/057_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/058_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/059_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/060_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/061_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/062_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/063_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/064_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/065_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/066_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/067_imgs.npy', '/content/drive/MyDrive/FA20_CS446_Project_Data/data_pub/validation/068_imgs.npy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJf3ZzM3pT4g"
      },
      "source": [
        "train_data = torch.utils.data.DataLoader(np_Dataset(t_d+v_d, t_l+v_l), shuffle=True, num_workers=4, pin_memory=True)\r\n",
        "val_data = torch.utils.data.DataLoader(np_final_dataset(test), num_workers=4, pin_memory=True)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoFPWig3sdi0"
      },
      "source": [
        "#PyTorch\r\n",
        "\r\n",
        "class DiceBCELoss(nn.Module):\r\n",
        "    def __init__(self, weight=None, size_average=True):\r\n",
        "        super(DiceBCELoss, self).__init__()\r\n",
        "\r\n",
        "    def forward(self, inputs, targets, smooth=1):\r\n",
        "        \r\n",
        "        # comment out if your model contains a sigmoid or equivalent activation layer\r\n",
        "        # inputs = F.sigmoid(inputs)       \r\n",
        "        \r\n",
        "        #flatten label and prediction tensors\r\n",
        "        inputs = inputs.view(-1)\r\n",
        "        targets = targets.view(-1)\r\n",
        "        \r\n",
        "        intersection = (inputs * targets).sum()                            \r\n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \r\n",
        "        BCE = func.binary_cross_entropy(inputs, targets, reduction='mean')\r\n",
        "        Dice_BCE = BCE + dice_loss\r\n",
        "        \r\n",
        "        return Dice_BCE"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0JlQu0XGU_Y"
      },
      "source": [
        "class BinaryDiceLoss(nn.Module):\r\n",
        "    \"\"\"Dice loss of binary class\r\n",
        "    Args:\r\n",
        "        smooth: A float number to smooth loss, and avoid NaN error, default: 1\r\n",
        "        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\r\n",
        "        predict: A tensor of shape [N, *]\r\n",
        "        target: A tensor of shape same with predict\r\n",
        "        reduction: Reduction method to apply, return mean over batch if 'mean',\r\n",
        "            return sum if 'sum', return a tensor of shape [N,] if 'none'\r\n",
        "    Returns:\r\n",
        "        Loss tensor according to arg reduction\r\n",
        "    Raise:\r\n",
        "        Exception if unexpected reduction\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, smooth=1, p=2, reduction='mean'):\r\n",
        "        super(BinaryDiceLoss, self).__init__()\r\n",
        "        self.smooth = smooth\r\n",
        "        self.p = p\r\n",
        "        self.reduction = reduction\r\n",
        "\r\n",
        "    def forward(self, predict, target):\r\n",
        "        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\r\n",
        "        predict = predict.contiguous().view(predict.shape[0], -1)\r\n",
        "        target = target.contiguous().view(target.shape[0], -1)\r\n",
        "\r\n",
        "        num = torch.sum(torch.mul(predict, target), dim=1) + self.smooth\r\n",
        "        den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.smooth\r\n",
        "\r\n",
        "        loss = 1 - num / den\r\n",
        "\r\n",
        "        if self.reduction == 'mean':\r\n",
        "            return loss.mean()\r\n",
        "        elif self.reduction == 'sum':\r\n",
        "            return loss.sum()\r\n",
        "        elif self.reduction == 'none':\r\n",
        "            return loss\r\n",
        "        else:\r\n",
        "            raise Exception('Unexpected reduction {}'.format(self.reduction))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class DiceLoss(nn.Module):\r\n",
        "    \"\"\"Dice loss, need one hot encode input\r\n",
        "    Args:\r\n",
        "        weight: An array of shape [num_classes,]\r\n",
        "        ignore_index: class index to ignore\r\n",
        "        predict: A tensor of shape [N, C, *]\r\n",
        "        target: A tensor of same shape with predict\r\n",
        "        other args pass to BinaryDiceLoss\r\n",
        "    Return:\r\n",
        "        same as BinaryDiceLoss\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, weight=None, ignore_index=None, **kwargs):\r\n",
        "        super(DiceLoss, self).__init__()\r\n",
        "        self.kwargs = kwargs\r\n",
        "        self.weight = weight\r\n",
        "        self.ignore_index = ignore_index\r\n",
        "\r\n",
        "    def forward(self, predict, target):\r\n",
        "        assert predict.shape == target.shape, 'predict & target shape do not match'\r\n",
        "        dice = BinaryDiceLoss(**self.kwargs)\r\n",
        "        total_loss = 0\r\n",
        "        predict = func.softmax(predict, dim=1)\r\n",
        "\r\n",
        "        for i in range(target.shape[1]):\r\n",
        "            if i != self.ignore_index:\r\n",
        "                dice_loss = dice(predict[:, i], target[:, i])\r\n",
        "                if self.weight is not None:\r\n",
        "                    assert self.weight.shape[0] == target.shape[1], \\\r\n",
        "                        'Expect weight shape [{}], get[{}]'.format(target.shape[1], self.weight.shape[0])\r\n",
        "                    dice_loss *= self.weight[i]\r\n",
        "                total_loss += dice_loss\r\n",
        "\r\n",
        "        return total_loss/target.shape[1]\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zPUqM62LrtV"
      },
      "source": [
        "def bbox3(img):\r\n",
        "    \"\"\"\r\n",
        "    compute bounding box of the nonzero image pixels\r\n",
        "    :param img: input image\r\n",
        "    :return: bbox with shape (2,3) and contents [min,max]\r\n",
        "    \"\"\"\r\n",
        "    rows = np.any(img, axis=1)\r\n",
        "    rows = np.any(rows, axis=1)\r\n",
        "\r\n",
        "    cols = np.any(img, axis=0)\r\n",
        "    cols = np.any(cols, axis=1)\r\n",
        "\r\n",
        "    slices = np.any(img, axis=0)\r\n",
        "    slices = np.any(slices, axis=0)\r\n",
        "\r\n",
        "    rows = np.where(rows)\r\n",
        "    cols = np.where(cols)\r\n",
        "    slices = np.where(slices)\r\n",
        "    if (rows[0].shape[0] > 0):\r\n",
        "        rmin, rmax = rows[0][[0, -1]]\r\n",
        "        cmin, cmax = cols[0][[0, -1]]\r\n",
        "        smin, smax = slices[0][[0, -1]]\r\n",
        "\r\n",
        "        return np.array([[rmin, cmin, smin], [rmax, cmax, smax]])\r\n",
        "    return np.array([[-1,-1,-1],[0,0,0]])\r\n",
        "\r\n",
        "def get_bbox(data):\r\n",
        "    bboxes = np.stack([bbox3(d) for d in data],axis=0)\r\n",
        "    return np.stack([np.min(bboxes[:,0],axis=0),np.max(bboxes[:,1],axis=0)],axis=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCkaX_p6MRb9"
      },
      "source": [
        "min = np.array([0,0,0])\r\n",
        "max = np.array([240, 240, 155])\r\n",
        "\r\n",
        "count = 0\r\n",
        "count2 = 0\r\n",
        "crop_size = np.array([128, 128, 128])\r\n",
        "\r\n",
        "def crop(t, l):\r\n",
        "  t = t.numpy()[0]\r\n",
        "  l = func.one_hot(l, num_classes=4)[0]\r\n",
        "  l= l.permute(3, 0, 1, 2).numpy()\r\n",
        "  # print(l.shape)\r\n",
        "  _, w, h, d = l.shape\r\n",
        "  if w < 128:\r\n",
        "    left_w = (128-w)//2\r\n",
        "    right_w = 128 - w - left_w\r\n",
        "    t = np.pad(t, ((0, 0), (left_w, right_w), (0,0), (0,0)), mode='edge')\r\n",
        "    l = np.pad(l, ((0,0), (left_w, right_w), (0,0), (0,0)), mode='edge')\r\n",
        "  if h < 128:\r\n",
        "    left_h = (128-h)//2\r\n",
        "    right_h = 128-h-left_h\r\n",
        "    t = np.pad(t, ((0, 0), (0,0), (left_h, right_h), (0,0)), mode='edge')\r\n",
        "    l = np.pad(l, ( (0,0), (0,0), (left_h, right_h), (0,0)), mode='edge')\r\n",
        "  if d < 128:\r\n",
        "    left_d = (128-d)//2\r\n",
        "    right_d = 128-d-left_d\r\n",
        "    t = np.pad(t, ((0, 0), (0,0), (0,0), (left_d, right_d)), mode='edge')\r\n",
        "    l = np.pad(l, ((0,0),  (0,0), (0,0), (left_d, right_d)), mode='edge')\r\n",
        "\r\n",
        "  b = get_bbox(t)\r\n",
        "  # print(t.shape)\r\n",
        "  size = b[1] - b[0]\r\n",
        "  # print(b, size)\r\n",
        "  \r\n",
        "  output = np.zeros(shape=(t.shape[0],)+tuple(crop_size))\r\n",
        "  out_annotation = np.zeros(shape=output.shape)\r\n",
        "  \r\n",
        "  diff = np.array(crop_size) - np.array(size)\r\n",
        "  low = diff // 2\r\n",
        "  high = low - diff\r\n",
        "  bbox = b - np.stack([low,high])\r\n",
        "\r\n",
        "  index_input_min = bbox[0] #np.maximum(bbox[0],min)\r\n",
        "  index_input_max = bbox[1] # np.minimum(bbox[1],max)\r\n",
        "  \r\n",
        "  size =  bbox[1] - bbox[0]\r\n",
        "\r\n",
        "  # print(size)\r\n",
        "  \r\n",
        "\r\n",
        "  index_output_min = crop_size//2 - size//2 \r\n",
        "  index_output_max = crop_size//2 + size - size//2\r\n",
        "\r\n",
        "  # print(l.shape, out_annotation.shape, t.shape, index_input_min, index_input_max, index_output_min, index_output_max)\r\n",
        "  \r\n",
        "  output[:,index_output_min[0]:index_output_max[0],index_output_min[1]:index_output_max[1],index_output_min[2]:index_output_max[2]] =\\\r\n",
        "  t[:,index_input_min[0]:index_input_max[0],index_input_min[1]:index_input_max[1],index_input_min[2]:index_input_max[2]]\r\n",
        "  \r\n",
        "  out_annotation[:,index_output_min[0]:index_output_max[0],index_output_min[1]:index_output_max[1],index_output_min[2]:index_output_max[2]] =\\\r\n",
        "  l[:,index_input_min[0]:index_input_max[0],index_input_min[1]:index_input_max[1],index_input_min[2]:index_input_max[2]]\r\n",
        "\r\n",
        "  return output, out_annotation, l.shape, (index_input_min, index_input_max)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_v5rkKdY_gg",
        "outputId": "cb59d168-1563-4f1f-a887-b37643e3f9b3"
      },
      "source": [
        "import model\r\n",
        "import loss\r\n",
        "import weight_init\r\n",
        "\r\n",
        "\r\n",
        "criterion = [loss.Dice_loss_joint(index=0,priority=1).cuda(), loss.BCE_Loss(index=0, bg_weight=1e-2).cuda()]\r\n",
        "enc_layers = [1,2,2,4,4,4]\r\n",
        "dec_layers = [1,1,1,1,1,1]\r\n",
        "number_of_channels=[int(16*2**i) for i in range(1,1+len(enc_layers))]\r\n",
        "number_of_channels[4] = number_of_channels[5] = 320\r\n",
        "model = model.UNet(depth=len(enc_layers), encoder_layers=enc_layers, decoder_layers=dec_layers, number_of_channels=number_of_channels, number_of_outputs=4).float()\r\n",
        "model.apply(weight_init.weight_init)\r\n",
        "\r\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNet [32, 64, 128, 256, 320, 320]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (encoder_convs): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Residual(\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "        )\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Residual(\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "        )\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Residual(\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(128, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "        )\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (3): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Residual(\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(256, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "        )\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (3): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Residual(\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "        )\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (3): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (upsampling): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Trilinear()\n",
              "      (1): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Trilinear()\n",
              "      (1): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Trilinear()\n",
              "      (1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Trilinear()\n",
              "      (1): Conv3d(320, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Trilinear()\n",
              "      (1): Conv3d(320, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder_convs): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Residual(\n",
              "        (conv1): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (conv2): conv(\n",
              "          (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "        )\n",
              "        (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "        (norm1): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "        (norm2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder_convs1x1): ModuleList(\n",
              "    (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    (1): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    (2): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    (3): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    (4): Conv3d(640, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "    (5): Conv3d(640, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "  )\n",
              "  (attention_convs): ModuleList()\n",
              "  (upsampling_distance): ModuleList()\n",
              "  (conv_input): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "  (norm_input): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
              "  (conv_first): Sequential(\n",
              "    (0): Residual(\n",
              "      (conv1): conv(\n",
              "        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): conv(\n",
              "        (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (relu1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (relu2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
              "      (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
              "    )\n",
              "  )\n",
              "  (conv_output): Conv3d(32, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (softmax): Softmax(dim=1)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ0FRhAhjp2F",
        "outputId": "c916e12e-c915-465b-827a-eaa2b4ea60d3"
      },
      "source": [
        "import metrics\r\n",
        "import gc\r\n",
        "import loss\r\n",
        "\r\n",
        "\r\n",
        "model = nn.DataParallel(model).cuda()\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), **{\"lr\": 2e-5,\"weight_decay\": 1e-6,\"amsgrad\": True})\r\n",
        "\r\n",
        "scheduler=torch.optim.lr_scheduler.StepLR(optimizer=optimizer, **{\"step_size\": 16000, \"gamma\": 0.5})\r\n",
        "\r\n",
        "criterion = DiceLoss().cuda()\r\n",
        "gc.collect()\r\n",
        "\r\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcg0W0mu0dNX"
      },
      "source": [
        "from metrics import Metrics\r\n",
        "\r\n",
        "class Dice(Metrics):\r\n",
        "    def __init__(self, name='Dice', input_index=0,target_index=0, classes=4):\r\n",
        "        super(Dice, self).__init__(name)\r\n",
        "        self.input_index=input_index\r\n",
        "        self.target_index=target_index\r\n",
        "        self.classes = classes\r\n",
        "\r\n",
        "    def update(self, ground, predict):\r\n",
        "        pred = predict[self.input_index].detach()\r\n",
        "        gr = ground[self.target_index].detach()\r\n",
        "\r\n",
        "        assert (gr.shape == pred.shape)\r\n",
        "\r\n",
        "        pred = (pred > 0.25)#torch.argmax(pred, dim=1).long().view(pred.size(0),-1)\r\n",
        "        gr = (gr > 0.25)#torch.argmax(gr, dim=1).long().view(gr.size(0),-1)\r\n",
        "\r\n",
        "        result = np.zeros(self.classes)\r\n",
        "\r\n",
        "        for i in range(0, self.classes):\r\n",
        "            p = pred[i].float().view(-1)#(pred == i).float()\r\n",
        "            g = gr[i].float().view(-1)#(gr == i).float()\r\n",
        "\r\n",
        "            numerator = (p * g).sum().cpu().numpy()\r\n",
        "            denominator = (p + g).sum().cpu().numpy()\r\n",
        "\r\n",
        "            r = 2 * numerator / denominator\r\n",
        "            if np.isnan(r):\r\n",
        "              r = 1\r\n",
        "\r\n",
        "            result[i] = r\r\n",
        "\r\n",
        "        self.accumulator = self.accumulator + np.mean(result)\r\n",
        "\r\n",
        "        self.samples += 1\r\n",
        "\r\n",
        "metric = Dice()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5H3hAwTsYVR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESJKgSFBsXvz",
        "outputId": "53a9c118-d719-4e29-e283-0bef325da94c"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/FA20_CS446_Project_Data/data_pub /content/data_pub"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sqiEz9x4_5HE",
        "outputId": "89176598-4721-4b48-a196-4c2fdf048053"
      },
      "source": [
        "num_epochs = 50\r\n",
        "\r\n",
        "for i in range(num_epochs):\r\n",
        "  metric.reset()\r\n",
        "  model.cuda()\r\n",
        "  model.train()\r\n",
        "  optimizer.zero_grad()\r\n",
        "  count = 0\r\n",
        "  for t, l in train_data:\r\n",
        "    \r\n",
        "    l =l.long()\r\n",
        "    # print(l[l!=0])\r\n",
        "    data, seg, og, _ = crop(t, l)\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    data = torch.from_numpy(data[np.newaxis,:,:,:,:]).float().to(device)\r\n",
        "    seg = torch.from_numpy(seg[np.newaxis,:,:,:,:]).float().to(device)\r\n",
        "\r\n",
        "\r\n",
        "    ret = model(data)[0]\r\n",
        "\r\n",
        "    # print(ret.shape, seg.shape)\r\n",
        "    loss = criterion(ret, seg)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    if count % 2:\r\n",
        "      optimizer.step()\r\n",
        "      optimizer.zero_grad()\r\n",
        "      scheduler.step()\r\n",
        "\r\n",
        "    metric.update(seg, ret)\r\n",
        "    print(count, metric.get())\r\n",
        "\r\n",
        "    \r\n",
        "    count += 1\r\n",
        "    \r\n",
        "\r\n",
        "  print(\"epoch {}: {}\".format(i, metric.get()))\r\n",
        "  \r\n",
        "# print(count)\r\n",
        "# print(count2)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0.18494417323427115\n",
            "1 0.18955285910563563\n",
            "2 0.20805636164868813\n",
            "3 0.2185704175845247\n",
            "4 0.22455823182682075\n",
            "5 0.23024924804579353\n",
            "6 0.23239834881348403\n",
            "7 0.23405145916442296\n",
            "8 0.23521479679637253\n",
            "9 0.23883854546277075\n",
            "10 0.23937752266860376\n",
            "11 0.2400263934747413\n",
            "12 0.24002478167098779\n",
            "13 0.24053683922568864\n",
            "14 0.24077584225061904\n",
            "15 0.24070509864437756\n",
            "16 0.2423247298271947\n",
            "17 0.24237145274954733\n",
            "18 0.2426673262859648\n",
            "19 0.2429265552998332\n",
            "20 0.24316365959499886\n",
            "21 0.2447298749923333\n",
            "22 0.24480349786398006\n",
            "23 0.24492444790447268\n",
            "24 0.248003307887039\n",
            "25 0.24963413461316514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-84:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-b4ee4ce2c079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp0qNQUS6n7m"
      },
      "source": [
        "class Dice_Val(Metrics):\r\n",
        "    def __init__(self, name='Dice', input_index=0,target_index=0, classes=4):\r\n",
        "        super(Dice_Val, self).__init__(name)\r\n",
        "        self.input_index=input_index\r\n",
        "        self.target_index=target_index\r\n",
        "        self.classes = classes\r\n",
        "\r\n",
        "    def update(self, ground, predict):\r\n",
        "        pred = predict[self.input_index].detach().cpu().numpy()\r\n",
        "        gr = ground[self.target_index].detach().cpu().numpy()\r\n",
        "\r\n",
        "        assert (gr.shape == pred.shape)\r\n",
        "\r\n",
        "        pred = np.where(pred > 0.25, 1.0, 0.0)#torch.argmax(pred, dim=1).long().view(pred.size(0),-1)\r\n",
        "        # gr = (gr > 0.25)#torch.argmax(gr, dim=1).long().view(gr.size(0),-1)\r\n",
        "\r\n",
        "        result = np.zeros(self.classes)\r\n",
        "\r\n",
        "        for i in range(0, self.classes):\r\n",
        "            # p = pred[i].float().view(-1)#(pred == i).float()\r\n",
        "            # g = gr[i].float().view(-1)#(gr == i).float()\r\n",
        "\r\n",
        "            numerator = np.sum(pred[i] * gr[i])\r\n",
        "            denominator = np.sum(pred[i] + gr[i])\r\n",
        "\r\n",
        "            r = 2 * numerator / denominator\r\n",
        "            if np.isnan(r):\r\n",
        "              r = 1\r\n",
        "\r\n",
        "            result[i] = r\r\n",
        "\r\n",
        "        self.accumulator = self.accumulator + np.mean(result)\r\n",
        "\r\n",
        "        self.samples += 1\r\n",
        "\r\n",
        "metric_val = Dice_Val()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "AS5CXHQwLL1l",
        "outputId": "eaea47e3-d80c-40e4-f6c9-c273b2ef0b03"
      },
      "source": [
        "\r\n",
        "    \r\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-1b3bd66889fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TltMuUDRBLwu"
      },
      "source": [
        "min = np.array([0,0,0])\r\n",
        "max = np.array([240, 240, 155])\r\n",
        "\r\n",
        "count = 0\r\n",
        "count2 = 0\r\n",
        "crop_size = np.array([128, 128, 128])\r\n",
        "\r\n",
        "def crop2(t):\r\n",
        "  t = t.numpy()[0]\r\n",
        "  # print(l.shape)\r\n",
        "  _, w, h, d = t.shape\r\n",
        "  if w < 128:\r\n",
        "    left_w = (128-w)//2\r\n",
        "    right_w = 128 - w - left_w\r\n",
        "    t = np.pad(t, ((0, 0), (left_w, right_w), (0,0), (0,0)), mode='edge')\r\n",
        "  if h < 128:\r\n",
        "    left_h = (128-h)//2\r\n",
        "    right_h = 128-h-left_h\r\n",
        "    t = np.pad(t, ((0, 0), (0,0), (left_h, right_h), (0,0)), mode='edge')\r\n",
        "  if d < 128:\r\n",
        "    left_d = (128-d)//2\r\n",
        "    right_d = 128-d-left_d\r\n",
        "    t = np.pad(t, ((0, 0), (0,0), (0,0), (left_d, right_d)), mode='edge')\r\n",
        "\r\n",
        "  b = get_bbox(t)\r\n",
        "  # print(t.shape)\r\n",
        "  size = b[1] - b[0]\r\n",
        "  # print(b, size)\r\n",
        "  \r\n",
        "  output = np.zeros(shape=(t.shape[0],)+tuple(crop_size))\r\n",
        "  \r\n",
        "  diff = np.array(crop_size) - np.array(size)\r\n",
        "  low = diff // 2\r\n",
        "  high = low - diff\r\n",
        "  bbox = b - np.stack([low,high])\r\n",
        "\r\n",
        "  index_input_min = bbox[0] #np.maximum(bbox[0],min)\r\n",
        "  index_input_max = bbox[1] # np.minimum(bbox[1],max)\r\n",
        "  \r\n",
        "  size =  bbox[1] - bbox[0]\r\n",
        "\r\n",
        "  # print(size)\r\n",
        "  \r\n",
        "\r\n",
        "  index_output_min = crop_size//2 - size//2 \r\n",
        "  index_output_max = crop_size//2 + size - size//2\r\n",
        "\r\n",
        "  # print(l.shape, out_annotation.shape, t.shape, index_input_min, index_input_max, index_output_min, index_output_max)\r\n",
        "  \r\n",
        "  output[:,index_output_min[0]:index_output_max[0],index_output_min[1]:index_output_max[1],index_output_min[2]:index_output_max[2]] =\\\r\n",
        "  t[:,index_input_min[0]:index_input_max[0],index_input_min[1]:index_input_max[1],index_input_min[2]:index_input_max[2]]\r\n",
        "  \r\n",
        "\r\n",
        "  return output, (w, h, d), (index_input_min, index_input_max)\r\n",
        "\r\n",
        "\r\n",
        "def crop_to_og(seg_ret, og, min_max):\r\n",
        "  seg_ret = np.argmax(seg_ret, axis=0)\r\n",
        "\r\n",
        "  # print(seg_ret.shape, og)\r\n",
        "\r\n",
        "  w, h, d = og\r\n",
        "\r\n",
        "  index_input_min, index_input_max = min_max\r\n",
        "\r\n",
        "  if w > 128:\r\n",
        "    left_w = (w-128)//2\r\n",
        "    right_w = w - 128  - left_w\r\n",
        "    seg_ret = np.pad(seg_ret, ( (left_w, right_w), (0,0), (0,0)), mode='edge')\r\n",
        "  else:\r\n",
        "    left_w = (128-w)//2\r\n",
        "    right_w = 128 - w- left_w\r\n",
        "    seg_ret = seg_ret[left_w:128-right_w, :, :]\r\n",
        "  if h > 128:\r\n",
        "    left_h = (h-128)//2\r\n",
        "    right_h = h-128-left_h\r\n",
        "    seg_ret = np.pad(seg_ret, (  (0,0), (left_h, right_h), (0,0)), mode='edge')\r\n",
        "  else:\r\n",
        "    left_h = (128-h)//2\r\n",
        "    right_h = 128-h-left_h\r\n",
        "    seg_ret = seg_ret[:,left_h:128-right_h, :]\r\n",
        "  if d > 128:\r\n",
        "    left_d = (d-128)//2\r\n",
        "    right_d = d-128-left_d\r\n",
        "    seg_ret = np.pad(seg_ret, ( (0,0), (0,0), (left_d, right_d)), mode='edge')\r\n",
        "  else:\r\n",
        "    left_d = (128-d)//2\r\n",
        "    right_d = 128-d-left_d\r\n",
        "    seg_ret = seg_ret[:,:, left_d:128-right_d]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  return seg_ret\r\n",
        "  \r\n",
        "  "
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahjNpO0yrR9T"
      },
      "source": [
        "!rm -r /content/output/"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82e1lUr1Zf2S",
        "outputId": "df1cd292-d6b9-4481-d593-af807362c224"
      },
      "source": [
        "target_dir = \"/content/output/{}_seg.npy\"\r\n",
        "\r\n",
        "for i, t in enumerate(val_data):\r\n",
        "    data, og, max_min = crop2(t)\r\n",
        "\r\n",
        "    data = torch.from_numpy(data[np.newaxis,:,:,:,:]).float().to(device)\r\n",
        "\r\n",
        "    seg_ret = model(data)[0][0].detach().cpu().numpy()\r\n",
        "    # print(seg_ret.shape)\r\n",
        "    seg_ret = crop_to_og(seg_ret, og, max_min)\r\n",
        "    # print(len(seg_ret[seg_ret==1]))\r\n",
        "    np.save(target_dir.format(str(i+1).zfill(3)), seg_ret)\r\n",
        "\r\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo40ZBr5dk13",
        "outputId": "777bceff-7e79-4903-88b6-30b9d866e76b"
      },
      "source": [
        "!zip -r /content/output.zip /content/output"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/001_seg.npy (deflated 100%)\n",
            "  adding: content/output/028_seg.npy (deflated 100%)\n",
            "  adding: content/output/016_seg.npy (deflated 100%)\n",
            "  adding: content/output/068_seg.npy (deflated 100%)\n",
            "  adding: content/output/066_seg.npy (deflated 100%)\n",
            "  adding: content/output/005_seg.npy (deflated 100%)\n",
            "  adding: content/output/038_seg.npy (deflated 100%)\n",
            "  adding: content/output/021_seg.npy (deflated 100%)\n",
            "  adding: content/output/045_seg.npy (deflated 100%)\n",
            "  adding: content/output/048_seg.npy (deflated 100%)\n",
            "  adding: content/output/035_seg.npy (deflated 100%)\n",
            "  adding: content/output/018_seg.npy (deflated 100%)\n",
            "  adding: content/output/052_seg.npy (deflated 100%)\n",
            "  adding: content/output/051_seg.npy (deflated 100%)\n",
            "  adding: content/output/046_seg.npy (deflated 100%)\n",
            "  adding: content/output/042_seg.npy (deflated 100%)\n",
            "  adding: content/output/025_seg.npy (deflated 100%)\n",
            "  adding: content/output/030_seg.npy (deflated 100%)\n",
            "  adding: content/output/023_seg.npy (deflated 100%)\n",
            "  adding: content/output/026_seg.npy (deflated 100%)\n",
            "  adding: content/output/020_seg.npy (deflated 100%)\n",
            "  adding: content/output/054_seg.npy (deflated 100%)\n",
            "  adding: content/output/060_seg.npy (deflated 100%)\n",
            "  adding: content/output/061_seg.npy (deflated 100%)\n",
            "  adding: content/output/032_seg.npy (deflated 100%)\n",
            "  adding: content/output/019_seg.npy (deflated 100%)\n",
            "  adding: content/output/057_seg.npy (deflated 100%)\n",
            "  adding: content/output/059_seg.npy (deflated 100%)\n",
            "  adding: content/output/041_seg.npy (deflated 100%)\n",
            "  adding: content/output/006_seg.npy (deflated 100%)\n",
            "  adding: content/output/022_seg.npy (deflated 100%)\n",
            "  adding: content/output/067_seg.npy (deflated 100%)\n",
            "  adding: content/output/031_seg.npy (deflated 100%)\n",
            "  adding: content/output/012_seg.npy (deflated 100%)\n",
            "  adding: content/output/029_seg.npy (deflated 100%)\n",
            "  adding: content/output/033_seg.npy (deflated 100%)\n",
            "  adding: content/output/003_seg.npy (deflated 100%)\n",
            "  adding: content/output/004_seg.npy (deflated 100%)\n",
            "  adding: content/output/024_seg.npy (deflated 100%)\n",
            "  adding: content/output/017_seg.npy (deflated 100%)\n",
            "  adding: content/output/015_seg.npy (deflated 100%)\n",
            "  adding: content/output/002_seg.npy (deflated 100%)\n",
            "  adding: content/output/062_seg.npy (deflated 100%)\n",
            "  adding: content/output/034_seg.npy (deflated 100%)\n",
            "  adding: content/output/044_seg.npy (deflated 100%)\n",
            "  adding: content/output/043_seg.npy (deflated 100%)\n",
            "  adding: content/output/027_seg.npy (deflated 100%)\n",
            "  adding: content/output/010_seg.npy (deflated 100%)\n",
            "  adding: content/output/050_seg.npy (deflated 100%)\n",
            "  adding: content/output/047_seg.npy (deflated 100%)\n",
            "  adding: content/output/049_seg.npy (deflated 100%)\n",
            "  adding: content/output/013_seg.npy (deflated 100%)\n",
            "  adding: content/output/036_seg.npy (deflated 100%)\n",
            "  adding: content/output/014_seg.npy (deflated 100%)\n",
            "  adding: content/output/063_seg.npy (deflated 100%)\n",
            "  adding: content/output/065_seg.npy (deflated 100%)\n",
            "  adding: content/output/009_seg.npy (deflated 100%)\n",
            "  adding: content/output/008_seg.npy (deflated 100%)\n",
            "  adding: content/output/011_seg.npy (deflated 100%)\n",
            "  adding: content/output/055_seg.npy (deflated 100%)\n",
            "  adding: content/output/053_seg.npy (deflated 100%)\n",
            "  adding: content/output/039_seg.npy (deflated 100%)\n",
            "  adding: content/output/058_seg.npy (deflated 100%)\n",
            "  adding: content/output/037_seg.npy (deflated 100%)\n",
            "  adding: content/output/040_seg.npy (deflated 100%)\n",
            "  adding: content/output/064_seg.npy (deflated 100%)\n",
            "  adding: content/output/056_seg.npy (deflated 100%)\n",
            "  adding: content/output/007_seg.npy (deflated 100%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "S8O6gn5pM-yx",
        "outputId": "7d473a97-17c3-46e3-f242-ed3fd1ce0509"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        " \r\n",
        "# seg = seg.cpu().detach().numpy()\r\n",
        "# check = check.cpu().detach().numpy()\r\n",
        "\r\n",
        "print(seg.shape)\r\n",
        "print(check.shape)\r\n",
        "# new_loss = DiceLoss()\r\n",
        "# print(check)\r\n",
        "check = np.where(check > 0.25, 1.0, 0.0)\r\n",
        "# print(check)\r\n",
        "# print(new_loss(torch.from_numpy(check), torch.from_numpy(seg[np.newaxis,:,:,:,:])))\r\n",
        "\r\n",
        "# for i in range(128):\r\n",
        "  # print(np.sum(check[0,0,i]) - 128**2)\r\n",
        "\r\n",
        "plt.imshow(check[0, 3, 70])\r\n",
        "plt.figure()\r\n",
        "plt.imshow(seg[0, 3, 70])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 4, 128, 128, 128)\n",
            "(1, 4, 128, 128, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7feeac8a1eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvU8B1jSTr_A"
      },
      "source": [
        "sums = np.zeros(4)\r\n",
        "cum_sum = 0\r\n",
        "for t, l in train_data:\r\n",
        "  l = l.long()[0]\r\n",
        "  l = func.one_hot(l, num_classes=4).numpy()\r\n",
        "  # print(l.shape)\r\n",
        "\r\n",
        "  for i in range(4):\r\n",
        "    v = np.sum(l[:, :, :, i])\r\n",
        "    sums[i] += v\r\n",
        "    cum_sum += v\r\n",
        "  \r\n",
        "  # print(sums, cum_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pki3cSBXQbi-",
        "outputId": "d23d3e2c-23ab-4ed6-d19e-245bfcc6a94e"
      },
      "source": [
        "weights = torch.from_numpy((sums/cum_sum)**-1).cuda()\r\n",
        "\r\n",
        "print(weights)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  1.0325, 135.7554,  55.0987, 168.4151], device='cuda:0',\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}